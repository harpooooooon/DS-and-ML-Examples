---
title: Polyglot in Rstudio
author: Nipunjeet Gujral
output: hmtl_notebook
---

```{r setup, include=FALSE}
library(tidyverse)
library(rlang)
library(reticulate)
library(RSQLite)
library(jsonlite)
library(DBI)
library(gapminder)
library(gutenbergr)
```

```{r}
gapminder_sqllite_db <- dbConnect(RSQLite::SQLite(), ":memory:")
dbWriteTable(conn = gapminder_sqllite_db, "gapminder", gapminder::gapminder)
```

##SQL

Uing a SQL Code Chunk
```{r}
year <- 1987
country <- "Rwanda"
```

```{sql, connection = gapminder_sqllite_db, output.var = "quried_gapminder_data"}
SELECT * FROM gapminder WHERE year = ?year AND country = ?country
```


Using dplyr
```{r}
tbl(gapminder_sqllite_db,  "gapminder") %>% 
  filter(year == 1987, country == "Rwanda")
```


Using DBi
```{r}
DBI::dbGetQuery(con = gapminder_sqllite_db, 
                "SELECT * FROM gapminder WHERE year == 1987 AND country == 'Rwanda'")
```


##Python 

```{r}
reticulate::use_python(python = 'C:/Program Files (x86)/Python', required = TRUE)
```

```{r}
shakespeare_raw <- gutenberg_download(100) 
shakespear <- shakespeare_raw %>% 
  mutate(text = stringr::str_replace_all(text, "[:upper:]{2,}", ""))

for_dictionary <- shakespear %>% 
  unnest_tokens(word, text)

mos_common_words <- for_dictionary %>% 
  group_by(word) %>% 
  summarise(total = n()) %>% 
  ungroup() %>% 
  anti_join(stop_words) %>% 
  arrange(desc(total)) %>% 
  slice(1:100)

top_word_corpus <- for_dictionary %>% 
  filter(word %in% unique(mos_common_words)) %>% 
  pull(word) %>% 
  as.character ()

python_to_classify <- reticulate::r_to_py(top_word_corpus)
py_save_object(python_to_classify, "shakespear.pickle")

```



```{python engine.path = 'C:/Users/nipun/Anaconda3/python'}
import numpy as np
import pickle

raw_corpus_pickle = open("C:/Users/nipun/Documents/shakespear.pickle", "rb")
raw_corpus = pickle.load(raw_corpus_pickle)

texts = [[word for word in document.lower().split()] for document in raw_corpus]

from collections import defaultdict

processed_corpus = [[token for token in text] for text in texts]

from gensim import corpora

dictionary = corpora.Dictionary(processed_corpus)
bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]

from gensim import models
tfidf = models.TfidfModel(bow_corpus)

```















